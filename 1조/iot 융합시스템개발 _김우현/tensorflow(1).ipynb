{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.0.0-alpha0\n",
      "  Downloading https://files.pythonhosted.org/packages/c7/90/cf5e7fbf4a3c14b314e1ed6571eae1f9ad3b5e32a4e24b2b817466435a21/tensorflow-2.0.0a0-cp37-cp37m-win_amd64.whl (49.4MB)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\a\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (1.12.0)\n",
      "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow==2.0.0-alpha0)\n",
      "  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
      "Collecting astor>=0.6.0 (from tensorflow==2.0.0-alpha0)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow==2.0.0-alpha0)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/0d/7cbf64cac3f93617a2b6b079c0182e4a83a3e7a8964d3b0cc3d9758ba002/absl-py-0.8.0.tar.gz (102kB)\n",
      "Collecting gast>=0.2.0 (from tensorflow==2.0.0-alpha0)\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/04/4e36c33f8eb5c5b6c622a1f4859352a6acca7ab387257d4b3c191d23ec1d/gast-0.3.2.tar.gz\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.0.0-alpha0)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow==2.0.0-alpha0)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow==2.0.0-alpha0)\n",
      "  Downloading https://files.pythonhosted.org/packages/32/e7/478737fd426798caad32a2abb7cc63ddb4c12908d9e03471dd3c41992b05/grpcio-1.23.0-cp37-cp37m-win_amd64.whl (1.6MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in c:\\users\\a\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (1.16.2)\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow==2.0.0-alpha0)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow==2.0.0-alpha0)\n",
      "  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
      "Collecting google-pasta>=0.1.2 (from tensorflow==2.0.0-alpha0)\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\a\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (0.33.1)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow==2.0.0-alpha0)\n",
      "  Downloading https://files.pythonhosted.org/packages/46/8b/5e77963dac4a944a0c6b198c004fac4c85d7adc54221c288fc6ca9078072/protobuf-3.9.1-cp37-cp37m-win_amd64.whl (1.0MB)\n",
      "Requirement already satisfied: h5py in c:\\users\\a\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.9.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\a\\anaconda3\\lib\\site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.14.1)\n",
      "Collecting markdown>=2.6.8 (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\a\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (40.8.0)\n",
      "Building wheels for collected packages: absl-py, gast, termcolor\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\a\\AppData\\Local\\pip\\Cache\\wheels\\9a\\1e\\7a\\456008eb5e47fd5de792c6139df6d5b3d5f71d51c6a0b94799\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\a\\AppData\\Local\\pip\\Cache\\wheels\\59\\38\\c6\\234dc39b4f6951a0768fbc02d5b7207137a5b1d9094f0d54bf\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\a\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "Successfully built absl-py gast termcolor\n",
      "Installing collected packages: tf-estimator-nightly, astor, absl-py, gast, termcolor, keras-preprocessing, grpcio, keras-applications, protobuf, markdown, tb-nightly, google-pasta, tensorflow\n",
      "Successfully installed absl-py-0.8.0 astor-0.8.0 gast-0.3.2 google-pasta-0.1.7 grpcio-1.23.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 protobuf-3.9.1 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 termcolor-1.1.0 tf-estimator-nightly-1.14.0.dev2019030115\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.0.0-alpha0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow.keras.utils as utils\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터셋 준비하기\n",
    "X_train = np.array(\n",
    "[\n",
    "    1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9\n",
    "]\n",
    ")\n",
    "\n",
    "Y_train = np.array(\n",
    "[\n",
    "    2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18\n",
    "])\n",
    "\n",
    "X_val = np.array(\n",
    "[\n",
    "    1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9\n",
    "])\n",
    "\n",
    "Y_val = np.array(\n",
    "[\n",
    "    2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18,2,4,6,8,10,12,14,16,18\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189,)\n",
      "[1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1\n",
      " 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2\n",
      " 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3\n",
      " 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4\n",
      " 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5\n",
      " 6 7 8 9]\n",
      "(189,)\n",
      "[ 2  4  6  8 10 12 14 16 18  2  4  6  8 10 12 14 16 18  2  4  6  8 10 12\n",
      " 14 16 18  2  4  6  8 10 12 14 16 18  2  4  6  8 10 12 14 16 18  2  4  6\n",
      "  8 10 12 14 16 18  2  4  6  8 10 12 14 16 18  2  4  6  8 10 12 14 16 18\n",
      "  2  4  6  8 10 12 14 16 18  2  4  6  8 10 12 14 16 18  2  4  6  8 10 12\n",
      " 14 16 18  2  4  6  8 10 12 14 16 18  2  4  6  8 10 12 14 16 18  2  4  6\n",
      "  8 10 12 14 16 18  2  4  6  8 10 12 14 16 18  2  4  6  8 10 12 14 16 18\n",
      "  2  4  6  8 10 12 14 16 18  2  4  6  8 10 12 14 16 18  2  4  6  8 10 12\n",
      " 14 16 18  2  4  6  8 10 12 14 16 18  2  4  6  8 10 12 14 16 18]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train)\n",
    "print(Y_train.shape)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨링 전환\n",
    "Y_train = utils.to_categorical(Y_train,19)\n",
    "Y_val = utils.to_categorical(Y_val,19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1\n",
      " 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2\n",
      " 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3\n",
      " 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4\n",
      " 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5\n",
      " 6 7 8 9]\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(189, 19)\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "(27, 19)\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(Y_train)\n",
    "print(Y_train.shape)\n",
    "print(Y_val)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=38, input_dim=1, activation='elu'))\n",
    "model.add(Dense(units=19,  activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 189 samples, validate on 27 samples\n",
      "Epoch 1/500\n",
      "189/189 [==============================] - 0s 828us/sample - loss: 0.6824 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6744 - accuracy: 1.0000 - val_loss: 0.6711 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6725 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6726 - accuracy: 1.0000 - val_loss: 0.6699 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6716 - accuracy: 1.0000 - val_loss: 0.6697 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6731 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6723 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6727 - accuracy: 1.0000 - val_loss: 0.6693 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6720 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6721 - accuracy: 1.0000 - val_loss: 0.6691 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "189/189 [==============================] - ETA: 0s - loss: 0.6704 - accuracy: 1.00 - 0s 111us/sample - loss: 0.6713 - accuracy: 1.0000 - val_loss: 0.6689 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6714 - accuracy: 1.0000 - val_loss: 0.6689 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6721 - accuracy: 1.0000 - val_loss: 0.6688 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6706 - accuracy: 1.0000 - val_loss: 0.6686 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "189/189 [==============================] - 0s 485us/sample - loss: 0.6706 - accuracy: 1.0000 - val_loss: 0.6685 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6706 - accuracy: 1.0000 - val_loss: 0.6684 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6714 - accuracy: 1.0000 - val_loss: 0.6683 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6703 - accuracy: 1.0000 - val_loss: 0.6682 - val_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6707 - accuracy: 1.0000 - val_loss: 0.6681 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6703 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6719 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6704 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6702 - accuracy: 1.0000 - val_loss: 0.6676 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6699 - accuracy: 1.0000 - val_loss: 0.6675 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6703 - accuracy: 1.0000 - val_loss: 0.6673 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6712 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6701 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "189/189 [==============================] - 0s 127us/sample - loss: 0.6699 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6705 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6700 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6687 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6697 - accuracy: 1.0000 - val_loss: 0.6666 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6701 - accuracy: 1.0000 - val_loss: 0.6664 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6695 - accuracy: 1.0000 - val_loss: 0.6663 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6698 - accuracy: 1.0000 - val_loss: 0.6662 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6684 - accuracy: 1.0000 - val_loss: 0.6661 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6686 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6684 - accuracy: 1.0000 - val_loss: 0.6659 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6689 - accuracy: 1.0000 - val_loss: 0.6658 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6678 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6678 - accuracy: 1.0000 - val_loss: 0.6655 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6688 - accuracy: 1.0000 - val_loss: 0.6654 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6681 - accuracy: 1.0000 - val_loss: 0.6653 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6681 - accuracy: 1.0000 - val_loss: 0.6653 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "189/189 [==============================] - 0s 85us/sample - loss: 0.6685 - accuracy: 1.0000 - val_loss: 0.6651 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "189/189 [==============================] - 0s 79us/sample - loss: 0.6692 - accuracy: 1.0000 - val_loss: 0.6651 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6675 - accuracy: 1.0000 - val_loss: 0.6649 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6672 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6673 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6664 - accuracy: 1.0000 - val_loss: 0.6645 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6675 - accuracy: 1.0000 - val_loss: 0.6644 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6669 - accuracy: 1.0000 - val_loss: 0.6643 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6661 - accuracy: 1.0000 - val_loss: 0.6643 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "189/189 [==============================] - 0s 79us/sample - loss: 0.6671 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6678 - accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6669 - accuracy: 1.0000 - val_loss: 0.6638 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6661 - accuracy: 1.0000 - val_loss: 0.6637 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6659 - accuracy: 1.0000 - val_loss: 0.6636 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6664 - accuracy: 1.0000 - val_loss: 0.6636 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "189/189 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 1.00 - 0s 84us/sample - loss: 0.6659 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6655 - accuracy: 1.0000 - val_loss: 0.6633 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6659 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6653 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6660 - accuracy: 1.0000 - val_loss: 0.6630 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "189/189 [==============================] - 0s 85us/sample - loss: 0.6660 - accuracy: 1.0000 - val_loss: 0.6628 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6659 - accuracy: 1.0000 - val_loss: 0.6627 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6652 - accuracy: 1.0000 - val_loss: 0.6626 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6649 - accuracy: 1.0000 - val_loss: 0.6625 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6650 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6649 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6652 - accuracy: 1.0000 - val_loss: 0.6622 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6646 - accuracy: 1.0000 - val_loss: 0.6621 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6644 - accuracy: 1.0000 - val_loss: 0.6620 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6649 - accuracy: 1.0000 - val_loss: 0.6619 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "189/189 [==============================] - 0s 116us/sample - loss: 0.6648 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6649 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6644 - accuracy: 1.0000 - val_loss: 0.6615 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6653 - accuracy: 1.0000 - val_loss: 0.6614 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "189/189 [==============================] - 0s 74us/sample - loss: 0.6637 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6642 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "189/189 [==============================] - 0s 85us/sample - loss: 0.6640 - accuracy: 1.0000 - val_loss: 0.6611 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "189/189 [==============================] - ETA: 0s - loss: 0.6455 - accuracy: 1.00 - 0s 84us/sample - loss: 0.6640 - accuracy: 1.0000 - val_loss: 0.6610 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6638 - accuracy: 1.0000 - val_loss: 0.6609 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6638 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6631 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6635 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6624 - accuracy: 1.0000 - val_loss: 0.6604 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6633 - accuracy: 1.0000 - val_loss: 0.6603 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6625 - accuracy: 1.0000 - val_loss: 0.6602 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6625 - accuracy: 1.0000 - val_loss: 0.6602 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6627 - accuracy: 1.0000 - val_loss: 0.6600 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6623 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6623 - accuracy: 1.0000 - val_loss: 0.6598 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6627 - accuracy: 1.0000 - val_loss: 0.6597 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6619 - accuracy: 1.0000 - val_loss: 0.6596 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6629 - accuracy: 1.0000 - val_loss: 0.6594 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6625 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6631 - accuracy: 1.0000 - val_loss: 0.6592 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6630 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6624 - accuracy: 0.9841 - val_loss: 0.6590 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6608 - accuracy: 1.0000 - val_loss: 0.6589 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6618 - accuracy: 1.0000 - val_loss: 0.6588 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6618 - accuracy: 1.0000 - val_loss: 0.6586 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6617 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "189/189 [==============================] - 0s 116us/sample - loss: 0.6610 - accuracy: 1.0000 - val_loss: 0.6584 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6617 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6619 - accuracy: 1.0000 - val_loss: 0.6582 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6611 - accuracy: 1.0000 - val_loss: 0.6581 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6605 - accuracy: 1.0000 - val_loss: 0.6580 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6606 - accuracy: 1.0000 - val_loss: 0.6578 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 105us/sample - loss: 0.6600 - accuracy: 1.0000 - val_loss: 0.6578 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6611 - accuracy: 1.0000 - val_loss: 0.6576 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6600 - accuracy: 1.0000 - val_loss: 0.6575 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6604 - accuracy: 1.0000 - val_loss: 0.6574 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6596 - accuracy: 1.0000 - val_loss: 0.6573 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6602 - accuracy: 1.0000 - val_loss: 0.6572 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6590 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6597 - accuracy: 1.0000 - val_loss: 0.6570 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6589 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6594 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6583 - accuracy: 1.0000 - val_loss: 0.6566 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6595 - accuracy: 1.0000 - val_loss: 0.6565 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6589 - accuracy: 1.0000 - val_loss: 0.6564 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6596 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6580 - accuracy: 1.0000 - val_loss: 0.6562 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6602 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6590 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6583 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6585 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6582 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6577 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6582 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6581 - accuracy: 1.0000 - val_loss: 0.6554 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6581 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6577 - accuracy: 1.0000 - val_loss: 0.6551 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6575 - accuracy: 1.0000 - val_loss: 0.6550 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6575 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6574 - accuracy: 1.0000 - val_loss: 0.6548 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6569 - accuracy: 1.0000 - val_loss: 0.6547 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6564 - accuracy: 1.0000 - val_loss: 0.6546 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6575 - accuracy: 1.0000 - val_loss: 0.6544 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6567 - accuracy: 1.0000 - val_loss: 0.6543 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6570 - accuracy: 1.0000 - val_loss: 0.6542 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6570 - accuracy: 1.0000 - val_loss: 0.6541 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6567 - accuracy: 1.0000 - val_loss: 0.6541 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6565 - accuracy: 1.0000 - val_loss: 0.6539 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "189/189 [==============================] - 0s 105us/sample - loss: 0.6574 - accuracy: 1.0000 - val_loss: 0.6538 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6559 - accuracy: 1.0000 - val_loss: 0.6537 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6559 - accuracy: 1.0000 - val_loss: 0.6536 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6559 - accuracy: 0.9894 - val_loss: 0.6536 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6559 - accuracy: 1.0000 - val_loss: 0.6534 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6562 - accuracy: 1.0000 - val_loss: 0.6532 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6552 - accuracy: 1.0000 - val_loss: 0.6531 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6557 - accuracy: 1.0000 - val_loss: 0.6531 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6573 - accuracy: 1.0000 - val_loss: 0.6529 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6562 - accuracy: 1.0000 - val_loss: 0.6528 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6549 - accuracy: 1.0000 - val_loss: 0.6527 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6552 - accuracy: 1.0000 - val_loss: 0.6526 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6547 - accuracy: 1.0000 - val_loss: 0.6525 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6554 - accuracy: 1.0000 - val_loss: 0.6524 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6557 - accuracy: 1.0000 - val_loss: 0.6522 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6558 - accuracy: 1.0000 - val_loss: 0.6522 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6547 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6544 - accuracy: 1.0000 - val_loss: 0.6519 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6542 - accuracy: 1.0000 - val_loss: 0.6518 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6549 - accuracy: 1.0000 - val_loss: 0.6517 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6546 - accuracy: 1.0000 - val_loss: 0.6516 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6546 - accuracy: 1.0000 - val_loss: 0.6515 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6537 - accuracy: 1.0000 - val_loss: 0.6514 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6537 - accuracy: 1.0000 - val_loss: 0.6513 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6537 - accuracy: 1.0000 - val_loss: 0.6512 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6538 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6535 - accuracy: 1.0000 - val_loss: 0.6509 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6529 - accuracy: 1.0000 - val_loss: 0.6509 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6536 - accuracy: 1.0000 - val_loss: 0.6508 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6531 - accuracy: 1.0000 - val_loss: 0.6506 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6535 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6534 - accuracy: 1.0000 - val_loss: 0.6504 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6541 - accuracy: 1.0000 - val_loss: 0.6503 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6531 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6523 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6527 - accuracy: 1.0000 - val_loss: 0.6501 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6521 - accuracy: 1.0000 - val_loss: 0.6499 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6525 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6524 - accuracy: 1.0000 - val_loss: 0.6497 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6526 - accuracy: 1.0000 - val_loss: 0.6495 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6521 - accuracy: 1.0000 - val_loss: 0.6494 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6519 - accuracy: 1.0000 - val_loss: 0.6493 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6516 - accuracy: 1.0000 - val_loss: 0.6493 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6519 - accuracy: 1.0000 - val_loss: 0.6491 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6511 - accuracy: 1.0000 - val_loss: 0.6491 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6527 - accuracy: 1.0000 - val_loss: 0.6490 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6514 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6527 - accuracy: 1.0000 - val_loss: 0.6487 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6518 - accuracy: 1.0000 - val_loss: 0.6486 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6516 - accuracy: 1.0000 - val_loss: 0.6486 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6509 - accuracy: 1.0000 - val_loss: 0.6484 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6512 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6507 - accuracy: 1.0000 - val_loss: 0.6482 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6498 - accuracy: 1.0000 - val_loss: 0.6480 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6513 - accuracy: 1.0000 - val_loss: 0.6479 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6508 - accuracy: 1.0000 - val_loss: 0.6478 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6498 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6503 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6495 - accuracy: 1.0000 - val_loss: 0.6475 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6500 - accuracy: 1.0000 - val_loss: 0.6474 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6499 - accuracy: 1.0000 - val_loss: 0.6473 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6498 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6503 - accuracy: 1.0000 - val_loss: 0.6471 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6497 - accuracy: 1.0000 - val_loss: 0.6470 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6492 - accuracy: 1.0000 - val_loss: 0.6469 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6507 - accuracy: 1.0000 - val_loss: 0.6468 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6488 - accuracy: 1.0000 - val_loss: 0.6466 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6503 - accuracy: 1.0000 - val_loss: 0.6465 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6488 - accuracy: 1.0000 - val_loss: 0.6464 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6498 - accuracy: 1.0000 - val_loss: 0.6464 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6494 - accuracy: 1.0000 - val_loss: 0.6462 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6489 - accuracy: 1.0000 - val_loss: 0.6461 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6497 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6498 - accuracy: 1.0000 - val_loss: 0.6459 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6485 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6484 - accuracy: 1.0000 - val_loss: 0.6457 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6491 - accuracy: 1.0000 - val_loss: 0.6456 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6483 - accuracy: 1.0000 - val_loss: 0.6455 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6480 - accuracy: 1.0000 - val_loss: 0.6453 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6478 - accuracy: 1.0000 - val_loss: 0.6453 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6471 - accuracy: 1.0000 - val_loss: 0.6451 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6483 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "189/189 [==============================] - 0s 121us/sample - loss: 0.6476 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "189/189 [==============================] - 0s 121us/sample - loss: 0.6471 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6474 - accuracy: 1.0000 - val_loss: 0.6447 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "189/189 [==============================] - 0s 85us/sample - loss: 0.6476 - accuracy: 1.0000 - val_loss: 0.6447 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6471 - accuracy: 1.0000 - val_loss: 0.6446 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6473 - accuracy: 1.0000 - val_loss: 0.6445 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6466 - accuracy: 1.0000 - val_loss: 0.6443 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "189/189 [==============================] - 0s 85us/sample - loss: 0.6469 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6472 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6464 - accuracy: 1.0000 - val_loss: 0.6440 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6468 - accuracy: 1.0000 - val_loss: 0.6439 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "189/189 [==============================] - 0s 79us/sample - loss: 0.6466 - accuracy: 1.0000 - val_loss: 0.6438 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6459 - accuracy: 1.0000 - val_loss: 0.6436 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6459 - accuracy: 1.0000 - val_loss: 0.6436 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6453 - accuracy: 1.0000 - val_loss: 0.6434 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6469 - accuracy: 1.0000 - val_loss: 0.6434 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6457 - accuracy: 1.0000 - val_loss: 0.6433 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6458 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6448 - accuracy: 1.0000 - val_loss: 0.6430 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6453 - accuracy: 1.0000 - val_loss: 0.6429 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6449 - accuracy: 1.0000 - val_loss: 0.6428 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6464 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6458 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6448 - accuracy: 1.0000 - val_loss: 0.6425 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6449 - accuracy: 1.0000 - val_loss: 0.6425 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6449 - accuracy: 1.0000 - val_loss: 0.6423 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6439 - accuracy: 1.0000 - val_loss: 0.6422 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6446 - accuracy: 1.0000 - val_loss: 0.6420 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6444 - accuracy: 1.0000 - val_loss: 0.6420 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6444 - accuracy: 1.0000 - val_loss: 0.6418 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6451 - accuracy: 1.0000 - val_loss: 0.6418 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6440 - accuracy: 1.0000 - val_loss: 0.6416 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6450 - accuracy: 1.0000 - val_loss: 0.6415 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6440 - accuracy: 1.0000 - val_loss: 0.6414 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6448 - accuracy: 1.0000 - val_loss: 0.6413 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6442 - accuracy: 1.0000 - val_loss: 0.6412 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6446 - accuracy: 1.0000 - val_loss: 0.6412 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6436 - accuracy: 1.0000 - val_loss: 0.6410 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6432 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6433 - accuracy: 1.0000 - val_loss: 0.6408 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6437 - accuracy: 1.0000 - val_loss: 0.6407 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6427 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6433 - accuracy: 1.0000 - val_loss: 0.6405 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6429 - accuracy: 1.0000 - val_loss: 0.6404 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6429 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6434 - accuracy: 1.0000 - val_loss: 0.6401 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "189/189 [==============================] - 0s 116us/sample - loss: 0.6429 - accuracy: 1.0000 - val_loss: 0.6400 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6428 - accuracy: 1.0000 - val_loss: 0.6399 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6429 - accuracy: 1.0000 - val_loss: 0.6398 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6424 - accuracy: 1.0000 - val_loss: 0.6399 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6431 - accuracy: 1.0000 - val_loss: 0.6396 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6423 - accuracy: 1.0000 - val_loss: 0.6395 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6422 - accuracy: 1.0000 - val_loss: 0.6394 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6434 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6416 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6421 - accuracy: 1.0000 - val_loss: 0.6390 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6418 - accuracy: 1.0000 - val_loss: 0.6389 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6416 - accuracy: 1.0000 - val_loss: 0.6388 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6427 - accuracy: 1.0000 - val_loss: 0.6388 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6406 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6385 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6410 - accuracy: 1.0000 - val_loss: 0.6384 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6407 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6411 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6410 - accuracy: 1.0000 - val_loss: 0.6380 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6411 - accuracy: 1.0000 - val_loss: 0.6380 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "189/189 [==============================] - 0s 127us/sample - loss: 0.6409 - accuracy: 1.0000 - val_loss: 0.6379 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6405 - accuracy: 1.0000 - val_loss: 0.6377 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6410 - accuracy: 1.0000 - val_loss: 0.6376 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6405 - accuracy: 1.0000 - val_loss: 0.6375 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "189/189 [==============================] - 0s 85us/sample - loss: 0.6399 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6404 - accuracy: 1.0000 - val_loss: 0.6373 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6396 - accuracy: 1.0000 - val_loss: 0.6372 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6399 - accuracy: 1.0000 - val_loss: 0.6371 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6412 - accuracy: 1.0000 - val_loss: 0.6370 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6396 - accuracy: 1.0000 - val_loss: 0.6369 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6398 - accuracy: 1.0000 - val_loss: 0.6368 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6389 - accuracy: 1.0000 - val_loss: 0.6368 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6386 - accuracy: 1.0000 - val_loss: 0.6366 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6391 - accuracy: 1.0000 - val_loss: 0.6365 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6389 - accuracy: 1.0000 - val_loss: 0.6364 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "189/189 [==============================] - 0s 105us/sample - loss: 0.6382 - accuracy: 1.0000 - val_loss: 0.6363 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6391 - accuracy: 1.0000 - val_loss: 0.6362 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6382 - accuracy: 1.0000 - val_loss: 0.6361 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6394 - accuracy: 1.0000 - val_loss: 0.6360 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6384 - accuracy: 1.0000 - val_loss: 0.6359 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6384 - accuracy: 1.0000 - val_loss: 0.6357 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6394 - accuracy: 1.0000 - val_loss: 0.6356 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6385 - accuracy: 1.0000 - val_loss: 0.6355 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6380 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6385 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "189/189 [==============================] - 0s 116us/sample - loss: 0.6375 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6372 - accuracy: 1.0000 - val_loss: 0.6351 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6373 - accuracy: 1.0000 - val_loss: 0.6350 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6386 - accuracy: 1.0000 - val_loss: 0.6349 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6378 - accuracy: 1.0000 - val_loss: 0.6348 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6380 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6369 - accuracy: 1.0000 - val_loss: 0.6348 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6375 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6372 - accuracy: 1.0000 - val_loss: 0.6344 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6370 - accuracy: 1.0000 - val_loss: 0.6343 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6375 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6367 - accuracy: 1.0000 - val_loss: 0.6341 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6364 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6370 - accuracy: 1.0000 - val_loss: 0.6339 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6369 - accuracy: 1.0000 - val_loss: 0.6337 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6371 - accuracy: 1.0000 - val_loss: 0.6336 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6362 - accuracy: 1.0000 - val_loss: 0.6336 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6360 - accuracy: 1.0000 - val_loss: 0.6335 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6365 - accuracy: 1.0000 - val_loss: 0.6334 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6361 - accuracy: 1.0000 - val_loss: 0.6332 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6357 - accuracy: 1.0000 - val_loss: 0.6332 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6364 - accuracy: 1.0000 - val_loss: 0.6330 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6358 - accuracy: 1.0000 - val_loss: 0.6329 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6348 - accuracy: 1.0000 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6352 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6360 - accuracy: 1.0000 - val_loss: 0.6326 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6352 - accuracy: 1.0000 - val_loss: 0.6325 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6347 - accuracy: 1.0000 - val_loss: 0.6324 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6352 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6350 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6348 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6352 - accuracy: 1.0000 - val_loss: 0.6321 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6345 - accuracy: 1.0000 - val_loss: 0.6320 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6348 - accuracy: 1.0000 - val_loss: 0.6319 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6337 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6343 - accuracy: 1.0000 - val_loss: 0.6316 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6343 - accuracy: 1.0000 - val_loss: 0.6315 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6336 - accuracy: 1.0000 - val_loss: 0.6314 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6345 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6341 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6335 - accuracy: 1.0000 - val_loss: 0.6311 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6340 - accuracy: 1.0000 - val_loss: 0.6310 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6335 - accuracy: 1.0000 - val_loss: 0.6309 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6338 - accuracy: 1.0000 - val_loss: 0.6307 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6330 - accuracy: 1.0000 - val_loss: 0.6307 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "189/189 [==============================] - 0s 105us/sample - loss: 0.6331 - accuracy: 1.0000 - val_loss: 0.6305 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6338 - accuracy: 1.0000 - val_loss: 0.6304 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6329 - accuracy: 1.0000 - val_loss: 0.6304 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6328 - accuracy: 1.0000 - val_loss: 0.6303 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6324 - accuracy: 1.0000 - val_loss: 0.6302 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6333 - accuracy: 1.0000 - val_loss: 0.6301 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6333 - accuracy: 1.0000 - val_loss: 0.6301 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6326 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6328 - accuracy: 1.0000 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6325 - accuracy: 1.0000 - val_loss: 0.6297 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6324 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6317 - accuracy: 1.0000 - val_loss: 0.6294 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6324 - accuracy: 1.0000 - val_loss: 0.6293 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6318 - accuracy: 1.0000 - val_loss: 0.6292 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6317 - accuracy: 1.0000 - val_loss: 0.6291 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6317 - accuracy: 1.0000 - val_loss: 0.6290 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6315 - accuracy: 1.0000 - val_loss: 0.6289 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6316 - accuracy: 1.0000 - val_loss: 0.6288 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6310 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6314 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 116us/sample - loss: 0.6312 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6315 - accuracy: 1.0000 - val_loss: 0.6284 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "189/189 [==============================] - 0s 84us/sample - loss: 0.6312 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "189/189 [==============================] - 0s 85us/sample - loss: 0.6301 - accuracy: 1.0000 - val_loss: 0.6282 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "189/189 [==============================] - 0s 85us/sample - loss: 0.6309 - accuracy: 1.0000 - val_loss: 0.6281 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6308 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6304 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6314 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6304 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6306 - accuracy: 1.0000 - val_loss: 0.6276 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6303 - accuracy: 1.0000 - val_loss: 0.6275 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6298 - accuracy: 1.0000 - val_loss: 0.6275 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6294 - accuracy: 1.0000 - val_loss: 0.6273 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6294 - accuracy: 1.0000 - val_loss: 0.6272 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6292 - accuracy: 1.0000 - val_loss: 0.6271 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6309 - accuracy: 1.0000 - val_loss: 0.6270 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6303 - accuracy: 1.0000 - val_loss: 0.6269 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6288 - accuracy: 1.0000 - val_loss: 0.6267 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6287 - accuracy: 1.0000 - val_loss: 0.6266 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6294 - accuracy: 1.0000 - val_loss: 0.6266 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6288 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6292 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6290 - accuracy: 1.0000 - val_loss: 0.6262 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6292 - accuracy: 1.0000 - val_loss: 0.6261 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6282 - accuracy: 1.0000 - val_loss: 0.6261 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6292 - accuracy: 1.0000 - val_loss: 0.6260 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6286 - accuracy: 1.0000 - val_loss: 0.6258 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6290 - accuracy: 1.0000 - val_loss: 0.6257 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6284 - accuracy: 1.0000 - val_loss: 0.6256 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6280 - accuracy: 1.0000 - val_loss: 0.6255 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6285 - accuracy: 1.0000 - val_loss: 0.6254 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6280 - accuracy: 1.0000 - val_loss: 0.6253 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6282 - accuracy: 1.0000 - val_loss: 0.6252 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6290 - accuracy: 1.0000 - val_loss: 0.6251 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6281 - accuracy: 1.0000 - val_loss: 0.6250 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6290 - accuracy: 1.0000 - val_loss: 0.6249 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "189/189 [==============================] - 0s 85us/sample - loss: 0.6272 - accuracy: 1.0000 - val_loss: 0.6249 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6275 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6270 - accuracy: 1.0000 - val_loss: 0.6246 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6272 - accuracy: 1.0000 - val_loss: 0.6245 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6270 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6270 - accuracy: 1.0000 - val_loss: 0.6243 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6266 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6262 - accuracy: 1.0000 - val_loss: 0.6241 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6266 - accuracy: 1.0000 - val_loss: 0.6240 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6275 - accuracy: 1.0000 - val_loss: 0.6239 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6278 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6260 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6265 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6261 - accuracy: 1.0000 - val_loss: 0.6235 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6259 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6254 - accuracy: 1.0000 - val_loss: 0.6233 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6272 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6259 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6248 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6262 - accuracy: 1.0000 - val_loss: 0.6229 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6255 - accuracy: 1.0000 - val_loss: 0.6228 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6260 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "189/189 [==============================] - 0s 85us/sample - loss: 0.6254 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6254 - accuracy: 1.0000 - val_loss: 0.6225 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6246 - accuracy: 1.0000 - val_loss: 0.6225 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6251 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6252 - accuracy: 1.0000 - val_loss: 0.6222 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6247 - accuracy: 1.0000 - val_loss: 0.6221 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6249 - accuracy: 1.0000 - val_loss: 0.6220 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6254 - accuracy: 1.0000 - val_loss: 0.6219 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6237 - accuracy: 1.0000 - val_loss: 0.6218 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6259 - accuracy: 1.0000 - val_loss: 0.6217 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6237 - accuracy: 1.0000 - val_loss: 0.6216 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6239 - accuracy: 1.0000 - val_loss: 0.6215 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6240 - accuracy: 1.0000 - val_loss: 0.6214 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6239 - accuracy: 1.0000 - val_loss: 0.6214 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6236 - accuracy: 1.0000 - val_loss: 0.6213 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6237 - accuracy: 1.0000 - val_loss: 0.6211 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6245 - accuracy: 1.0000 - val_loss: 0.6210 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6244 - accuracy: 1.0000 - val_loss: 0.6209 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6237 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6239 - accuracy: 1.0000 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "189/189 [==============================] - 0s 116us/sample - loss: 0.6241 - accuracy: 1.0000 - val_loss: 0.6206 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6236 - accuracy: 1.0000 - val_loss: 0.6206 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6224 - accuracy: 1.0000 - val_loss: 0.6206 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6228 - accuracy: 1.0000 - val_loss: 0.6203 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6231 - accuracy: 1.0000 - val_loss: 0.6202 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6234 - accuracy: 1.0000 - val_loss: 0.6201 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6226 - accuracy: 1.0000 - val_loss: 0.6200 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6225 - accuracy: 1.0000 - val_loss: 0.6200 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6223 - accuracy: 1.0000 - val_loss: 0.6198 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6224 - accuracy: 1.0000 - val_loss: 0.6197 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6219 - accuracy: 1.0000 - val_loss: 0.6196 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6216 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6222 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6215 - accuracy: 1.0000 - val_loss: 0.6193 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6220 - accuracy: 1.0000 - val_loss: 0.6193 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6212 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "189/189 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 1.00 - 0s 85us/sample - loss: 0.6213 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6218 - accuracy: 1.0000 - val_loss: 0.6189 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6213 - accuracy: 1.0000 - val_loss: 0.6188 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6212 - accuracy: 1.0000 - val_loss: 0.6187 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6218 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "189/189 [==============================] - 0s 111us/sample - loss: 0.6215 - accuracy: 1.0000 - val_loss: 0.6185 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6211 - accuracy: 1.0000 - val_loss: 0.6184 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6212 - accuracy: 1.0000 - val_loss: 0.6183 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6218 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6201 - accuracy: 1.0000 - val_loss: 0.6181 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6212 - accuracy: 1.0000 - val_loss: 0.6180 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6200 - accuracy: 1.0000 - val_loss: 0.6179 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6209 - accuracy: 1.0000 - val_loss: 0.6178 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6206 - accuracy: 1.0000 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "189/189 [==============================] - 0s 100us/sample - loss: 0.6205 - accuracy: 1.0000 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6195 - accuracy: 1.0000 - val_loss: 0.6175 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6209 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6210 - accuracy: 1.0000 - val_loss: 0.6173 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "189/189 [==============================] - 0s 90us/sample - loss: 0.6209 - accuracy: 1.0000 - val_loss: 0.6172 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "189/189 [==============================] - 0s 95us/sample - loss: 0.6204 - accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "189/189 [==============================] - 0s 106us/sample - loss: 0.6198 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(X_train, Y_train, epochs=500, batch_size=10, verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 776us/sample - loss: 0.6170 - accuracy: 1.0000\n",
      "\n",
      "loss : 0.6169846240017149\n",
      "accuray : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 사용하기\n",
    "X_test = np.array([\n",
    "    1,2,3,4,5,6,7,8,9\n",
    "])\n",
    "Y_test = np.array([\n",
    "    [0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "    \n",
    "])\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=1)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
